## Results
Here we describe the functionality and interface for the visualizations and explain why they are useful for analyzing electrophysiological data.

#### SpectraVis
Functional network analysis is a growing area of neuroscience research, driven in part by technological improvements allowing us to record from more sensors simultaneously. However, as researchers record from more sensors, network analyses can become unwieldy and hard to interpret, because the number of possible network connections scales quadratically with the number of sensors (e.g. electrodes). Further, we expect neural processes to form dynamic networks that vary over time, frequency, and spatial scales (e.g. within and between brain regions), adding numerous dimensions to network analyses.

`SpectraVis` is an interactive visualization aimed at enhancing exploratory analysis of networks by allowing the user to efficiently: (1) compare task-related functional networks over time and frequency, (2) compare individual and associative measures on all sensor pairs (e.g. spectra, coherences), (3) compare different measures of association (e.g. correlation vs. coherence, binary vs. weighted networks), and (4) view networks at two spatial scales (sensor- and region-of-interest-level). The different views of `SpectraVis` are dynamically linked, highlighting relationships between the metrics in response to user interaction.

Figure @fig:SpectraVis shows a typical view of `SpectraVis`. The network view shows the anatomical location of the sensors (circles with sensor number) and edges (lines) weighted by the edge statistic (color of the line, measure of association between the sensors). In this example, the edges are binary, representing significant changes in local field potential coherence between *Speech* --- subjects reading aloud the words of the Gettysburg Address --- and *Silence* at a particular frequency (10 Hz) and time (187.5 ms after speech onset). The network has dense connectivity within and between primary motor and primary somatosensory cortices (M1 and S1). Users can compare between binary edge statistics, which categorically declare associations between sensors, and weighted edge statistics, which use continuous measures such as the raw coherence difference and z-scored coherence difference, via the edge statistic dropdown.

The controls can also be used to examine the evolution of the network over time using either the time slider, which can be dragged to a time of interest, or the play button, which will automatically move the time step forward. The user can compare networks at different frequency bands (for example, the network in the 8-13 Hz alpha band versus the 20-40 Hz gamma band) using the frequency slider.

One difficulty of analyzing networks is interpreting the edges between sensors, particularly if the network is a weighted network and there are many sensors. There often is not enough room in a visualization to display all the edges without much overlap. To solve this problem, we use two strategies: layout and filtering.

The network layout toggle controls where nodes are positioned (and consequently the edges between nodes). Because the networks are dynamic and may change based on time or frequency, `SpectraVis` offers a *topological* layout --- which models the nodes and edges as a physical system to limit the number of overlapping edges. There is also an *anatomical* layout which places the nodes according to the anatomical position defined in the JSON files.

Filtering edges and sensors allow the user to isolate subsets of the network --- reducing the number of comparisons needed to be made in any one view. Using the edge filter dropdown, the user can isolate the edges between sensors that reside within the same brain area (e.g. only auditory cortex - auditory cortex sensor pairs) or between sensors that have non-matching brain areas (e.g. only auditory cortex -- motor cortex sensor pairs).

Once the desired network view has been obtained, users can get further detail by clicking on a pair of sensors. This loads a sensor view (Figure 3, dotted box) which depicts the relationship (spectra, coherences) between a selected pair of sensors (circled in black, network view, sensors 85 and 90) at all times and frequencies. Here, the edge between M1 (sensor 90) and S1 (sensor 85) represents a 10 Hz increase in speech coherence relative to silence. The increase co-occurs with higher frequency beta (15-25Hz) power suppression on the M1 sensor. The user can investigate the relationship between the sensor pair and the network view by mousing over a time-frequency bin in the sensor view, which correspondingly updates the network view to the time-frequency bin under the cursor.

![A static screenshot of the `SpectraVis` interface with the ECOG overt reading data.](figures/SpectraVis.png){#fig:SpectraVis width=100%}

#### RasterVis
`RasterVis` incorporates two canonical visualizations for single and multiunit spiking data --- the raster plot and peri-event time histogram. The raster plot describes spike times for each trial relative to a trial event. The peri-event time histogram is a simple but useful summary of how, over a series of trials, the spike times are distributed across time bins relative to the time of a trial event. Because these two types of visualizations are familiar and represent the "raw" spiking data, they are an ideal building-block visualization. Furthermore, they can also be used to compare raw spiking data to model-generated data in order to check statistical modeling assumptions (posterior predictive checks) --- so they can be useful in understanding how models reflect the data.

`RasterVis` uses interactivity and animation to supplement the raster plot and peri-event time histogram in order to make it easier for the user to accomplish typical tasks in the analysis of spiking data (See Figure @fig:RasterVis for a screenshot of the `RasterVis` interface).

For example, `RasterVis` allows for dynamic alignment of spike times and "on-the-fly" computation of peri-event histograms relative to experimental trial events (e.g. visual stimuli, timing of rewards, presentation of fixation points). Animated transitions emphasize how spike timing relative to trial event relates to another. This helps a user quickly compare the timing of individual spikes and aggregate spiking (via histogram) to different cues and conditions. Different levels of aggregation (Gaussian smoothing) for the histogram can be compared as well.

`RasterVis` also allows for dynamic sorting by experimental task factors. This feature creates on-demand plots for each condition within the task factor. For example, if a task factor is a visual cue with two experimental conditions --- the color cue and the orientation cue --- sorting by the visual cue creates two plots for the color condition and the orientation condition. This is essential for multidimensional analysis which may compare several different factors and conditions.

Finally, `RasterVis` allows users to find and select neurons by subject, recording session, or name. This is useful for fast comparison between neurons, linking to other visualizations (other visualizations can directly link to a specific neuron by name via a parameter passed via the URL), and general exploratory analysis of the dataset.

![A static screenshot of the `RasterVis` interface.](figures/RasterVis.png){#fig:RasterVis width=100%}

#### GLMVis
A common analysis framework for characterizing the spiking response of neurons is the generalized linear model (GLM) [@harris_organization_2003; @pillow_spatiotemporal_2008;@mayo_dynamics_2015; @park_encoding_2014; @fernandes_saliency_2014] . GLMs can simultaneously estimate effects of experimental conditions, spike history (refractory period, bursting), non-linear firing rate changes over time, and dependence on other neurons [@truccolo_point_2004] --- making them useful for analyzing a wide range of experiments.

One consequence of being able to estimate many covariates simultaneously is the relationship of the effects becomes hard to understand because of the number of dimensions --- particularly if the covariates change over time and there are many neurons. Moreover, understanding the relationship between multiple covariates may be important to understanding *mixed selectivity* neurons [@rigotti_importance_2013]. These neurons are sensitive to a combination of sensory, motor and cognitive processes, appear in higher-order association brain regions such as parietal and prefrontal cortex [@park_encoding_2014; @rigotti_importance_2013], and may underlie the computation of complex behavior [@rigotti_internal_2010].

Therefore, we built `GLMVis`, an interactive visualization for GLMs, that: (1) shows the relationship between the multiple dimensions of the model fit over time, (2) allows filtering of neurons by effect size, brain area, and experimental subject, and (3) can be used to compare estimates from different models. To show the relationship between multiple dimensions, we use the parallel coordinate plots [@inselberg_plane_1985; @wegman_hyperdimensional_1990] --- a compact representation of multivariate data that links each dimension on parallel axes by a line.

Figure @fig:GLMVis shows a typical view of `RasterVis`. Each axis is a black horizontal line that corresponds to a dimension of the GLM. Non-parallel lines connect the dimensions and represent a single neuron. The intersection of the axes and non-parallel lines is the computed value of the neuron at that dimension. Dropdown menus allow the user to filter the neurons by their brain area or subject. The user can also filter by effect size by "brushing" along a desired axis --- holding and dragging the mouse to select neurons in the range of values. Multiple axes can be selected in order to investigate the associations between values in different dimensions.

![A static screenshot of the `GLMVis` interface.](figures/GLMVis.png){#fig:GLMVis width=100%}
